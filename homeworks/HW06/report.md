# HW06 – Report

> Файл: `homeworks/HW06/report.md`

## 1. Dataset

- **Датасет:** `S06-hw-dataset-04.csv`
- **Описание:** Синтетический датасет для бинарной классификации с 60 числовыми признаками (`f01`...`f60`). По структуре напоминает задачу Fraud Detection.
- **Размер:** 25 000 строк (18 750 Train / 6 250 Test), 62 столбца.
- **Целевая переменная:** `target`. Наблюдается сильный дисбаланс:
  - Класс 0 (Normal): ~95.1%
  - Класс 1 (Fraud): ~4.9%
- **Признаки:** Все признаки числовые, пропусков не обнаружено.

## 2. Protocol

- **Разбиение:** Train/Test в соотношении 75/25 (`test_size=0.25`).
- **Воспроизводимость:** `random_state=42`, `stratify=y` (для сохранения пропорции 95/5 в обучении и тесте).
- **Подбор гиперпараметров:** `GridSearchCV` на Train выборке (4 фолда, `StratifiedKFold`). Оптимизировали метрику `roc_auc`.
- **Метрики:**
  - **ROC-AUC (Основная):** Выбрана как главная метрика из-за дисбаланса классов. Показывает качество ранжирования.
  - **F1 Score:** Для оценки баланса Precision и Recall.
  - **Accuracy:** Приведена справочно (на дисбалансе она неинформативна).

## 3. Models

Сравнивались следующие модели (все, кроме Dummy, обучались с `class_weight='balanced'`):

1.  **DummyClassifier:** Baseline (стратегия `most_frequent`).
2.  **LogisticRegression:** Baseline из S05. Использовался `StandardScaler`.
3.  **DecisionTreeClassifier:** Одиночное дерево. Подбирались `max_depth` (лучшее: 5) и `min_samples_leaf` (лучшее: 50).
4.  **RandomForestClassifier:** Бэггинг. Подбирались `n_estimators`, `max_depth`. Лучшие параметры: `{'max_depth': None, 'min_samples_leaf': 2, 'n_estimators': 100}`.
5.  **HistGradientBoostingClassifier:** Градиентный бустинг (аналог LightGBM). Подбирались `learning_rate`, `max_iter`, `max_depth`.

## 4. Results

Результаты на отложенной тестовой выборке (Test):

| Model | Accuracy | F1 Score | ROC AUC |
| :--- | :--- | :--- | :--- |
| Dummy | 0.9509 | 0.0000 | 0.5000 |
| LogisticRegression | 0.7792 | 0.2573 | 0.8419 |
| DecisionTree | 0.8771 | 0.3663 | 0.8318 |
| **RandomForest** | **0.9709** | **0.5787** | **0.9113** |
| HistGradientBoosting | 0.9541 | 0.6189 | 0.8965 |

**Победитель:**
Модель **RandomForest** показала лучший результат по **ROC-AUC (0.911)**.
*Примечание:* HistGradientBoosting показал чуть более высокий F1-score (0.619), но по совокупному качеству ранжирования (AUC) Лес выиграл. Оба ансамбля значительно превзошли линейную модель и одиночное дерево.

## 5. Analysis

- **Устойчивость:** Использование кросс-валидации на 4 фолда при подборе параметров позволило найти робастные настройки. Разница между AUC на Train (обычно выше) и Test (0.91) адекватная, переобучение контролируется.
- **Ошибки (Confusion Matrix для RandomForest):**
  - **True Negatives:** 5943 (Все честные транзакции определены верно).
  - **False Positives:** 0 (Модель ни разу не назвала честного человека мошенником — очень высокая точность/Precision).
  - **False Negatives:** 125 (Пропущено около 40% мошенников).
  - **True Positives:** 182.
  *Вывод:* Модель получилась очень "осторожной" (Conservative). Она срабатывает только тогда, когда уверена на 100%.
- **Интерпретация (Permutation Importance):**
  Наиболее важные признаки для классификации: `f54`, `f53`, `f25`, `f41`, `f58`.
  Признак `f54` имеет самый значительный вклад в снижение ошибки. Линейные модели (LogReg) не давали такого качества, что говорит о сложной нелинейной природе зависимости этих признаков от таргета.

## 6. Conclusion

1.  **Ансамбли побеждают:** RandomForest и Boosting улучшили ROC-AUC на ~7-8 пунктов по сравнению с логистической регрессией. Объединение слабых моделей (деревьев) работает эффективно.
2.  **Одиночное дерево слабовато:** DecisionTree (AUC 0.83) оказалось даже хуже логистической регрессии (AUC 0.84). Одиночное дерево слишком нестабильно и "грубо" делит пространство.
3.  **Дисбаланс классов:** Параметр `class_weight='balanced'` помог моделям обращать внимание на редкий класс (1). Без этого Accuracy была бы 95%, но мы бы не нашли ни одного мошенника.
4.  **Важность метрик:** Если смотреть только на Accuracy, то Dummy (0.95) кажется лучше LogReg (0.78), хотя Dummy бесполезен. ROC-AUC и F1 дали честную картину.