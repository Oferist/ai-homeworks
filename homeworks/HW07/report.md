# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (1000 строк, 8 столбцов)
- Признаки: все числовые (`float64`).
- Пропуски: отсутствуют (но в пайплайне добавлен `SimpleImputer` для надежности).
- "Подлости" датасета: признаки имеют разный масштаб (требуется нормализация), присутствуют шумовые признаки, не несущие полезной информации для кластеризации.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (1000 строк, 3 столбца)
- Признаки: все числовые (`x1`, `x2`, `z_noise`).
- Пропуски: отсутствуют.
- "Подлости" датасета: явно выраженная нелинейная структура (вложенные формы/дуги) + наличие выбросов и отдельного шумового признака `z_noise`.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (1000 строк, 4 столбца)
- Признаки: все числовые.
- Пропуски: отсутствуют.
- "Подлости" датасета: кластеры имеют разную плотность (один плотный, другие более разреженные), что затрудняет подбор единого `eps` для DBSCAN. Также есть коррелирующие и шумовые признаки.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг:**
  - `SimpleImputer(strategy='mean')`: предобработка на случай пропусков.
  - `StandardScaler()`: обязательное масштабирование всех признаков к $\mu=0, \sigma=1$. Без этого шага евклидово расстояние (основа KMeans и DBSCAN) работало бы некорректно, отдавая приоритет признакам с большими значениями.
- **Поиск гиперпараметров:**
  - **KMeans:** перебор `k` в диапазоне от 2 до 10. Критерий выбора — максимум `silhouette_score` и визуальный анализ графика ("метод локтя").
  - **DBSCAN:** перебор `eps` от 0.1 до 0.8 с шагом ~0.05, `min_samples` фиксировали на уровне 4-5.
  - **Agglomerative:** перебор `k` от 2 до 6.
- **Метрики:**
  - `silhouette_score` (чем выше, тем лучше) — основная метрика.
  - `davies_bouldin_score` (чем ниже, тем лучше).
  - `calinski_harabasz_score` (чем выше, тем лучше).
  - Для DBSCAN: метрики считались только по объектам, не являющимся шумом (label ≠ -1), также отдельно фиксировалась доля шума.
- **Визуализация:**
  - PCA (2 компоненты) для итоговой отрисовки кластеров.
  - Графики зависимости метрик (Silhouette) от параметров ($k$ или $eps$).

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- **Dataset A:**
  - KMeans (поиск `k`, `random_state=42`, `n_init=10`).
  - AgglomerativeClustering (поиск `k`, `linkage='ward'`).
- **Dataset B:**
  - KMeans (поиск `k`, `random_state=42`, `n_init=10`).
  - DBSCAN (поиск `eps`, фиксированный `min_samples=5`).
- **Dataset C:**
  - KMeans (поиск `k`, `random_state=42`, `n_init=10`).
  - DBSCAN (поиск `eps`, фиксированный `min_samples=4`).

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- **Лучший метод и параметры:** KMeans, `k=2`.
- **Метрики:** Silhouette ≈ 0.522, Davies-Bouldin ≈ 0.685.
- **Если был DBSCAN:** не использовался как основной, но Agglomerative показал схожий результат.
- **Коротко:** Датасет состоит из двух хорошо разделенных "облаков". KMeans идеально нашел центры этих сфер. Высокий силуэт подтверждает отличное разделение.

### 4.2 Dataset B

- **Лучший метод и параметры:** DBSCAN, `eps=0.64` (параметр может варьироваться в зависимости от запуска, но этот дал лучший результат).
- **Метрики:** Silhouette ≈ 0.28 (на очищенных данных), доля шума ≈ 1.5%.
- **Если был DBSCAN:** Доля шума невелика, выбросы корректно отфильтрованы.
- **Коротко:** KMeans (даже при подборе $k$) провалился, разрезая дуги пополам. DBSCAN корректно выделил сложную геометрическую форму кластеров и отделил шумовые точки. Низкий силуэт объясняется невыпуклой формой кластеров, для которой эта метрика не идеальна.

### 4.3 Dataset C

- **Лучший метод и параметры:** KMeans, `k=3`.
- **Метрики:** Silhouette ≈ 0.316.
- **Если был DBSCAN:** Показал низкий результат (Silhouette ≈ 0.10) из-за проблем с разной плотностью.
- **Коротко:** Три кластера расположены достаточно близко, но имеют разную плотность. DBSCAN с единым `eps` либо склеивал их, либо терял разреженный кластер. KMeans оказался устойчивее и дал более адекватное разбиение на 3 группы, что подтверждается максимумом силуэта.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **Где KMeans "ломается":** На Dataset B (нелинейность). Он пытается строить выпуклые кластеры (соты Вороного), что физически не соответствует форме данных "месяцев" или "колец".
- **Где DBSCAN выигрывает:** На Dataset B. Он следует за плотностью точек и игнорирует форму, что позволяет выделять изогнутые структуры.
- **Влияние факторов:**
  - **Масштабирование:** Критично для Dataset A (разные шкалы).
  - **Плотность:** Разная плотность на Dataset C "убила" DBSCAN, сделав KMeans предпочтительным.
  - **Шум:** DBSCAN отлично справился с фильтрацией выбросов на Dataset B, тогда как KMeans вынужден был включать их в кластеры, сдвигая центроиды.

### 5.2 Устойчивость (обязательно для одного датасета)

- **Проверка:** Для Dataset A запускался KMeans 5 раз с разными `random_state` (43, 44, 45, 46, 47). Результаты сравнивались с базовым запуском (seed=42) через метрику Adjusted Rand Index (ARI).
- **Результат:** Во всех 5 запусках ARI был равен 1.0 (или крайне близок к нему).
- **Вывод:** Решение **устойчиво**. Структура данных (два явных облака) настолько четкая, что алгоритм сходится к одному и тому же глобальному оптимуму независимо от начальной инициализации центроидов.

### 5.3 Интерпретация кластеров

- **Как интерпретировали:**
  - Использовалась визуализация PCA (2D) для сопоставления геометрического положения точек и присвоенных меток.
  - Для Dataset B (DBSCAN): Кластеры 0 и 1 представляют собой сложные структуры данных, а метка -1 — это случайный шум, который следует исключить из анализа.
  - Для Dataset A/C: Кластеры интерпретируются как компактные группы объектов с похожими значениями признаков (центроиды).

## 6. Conclusion

1. Без `StandardScaler` distance-based методы (KMeans, DBSCAN) на данных с разными шкалами (Dataset A) дают неадекватные результаты.
2. Метрика `silhouette_score` хорошо подходит для оценки KMeans, но может вводить в заблуждение на невыпуклых кластерах (Dataset B), поэтому визуализация (PCA) обязательна.
3. Не существует универсального алгоритма: KMeans хорош для простых форм и разной плотности (Dataset C), DBSCAN незаменим для сложной геометрии и очистки от шума (Dataset B).
4. Протокол "честного" эксперимента требует фиксации препроцессинга и диапазона параметров до начала анализа, чтобы избежать подгонки под ответ.